<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>Natural Language Processing</title>
        <meta name='Generator' content='Zim 0.53'>
        <meta http-equiv="cache-control" content="no-cache">
        <link rel="stylesheet" type="text/css" href="http://pointtonull.github.com/style.css" />
    </head>
    <body>
        <div class="page">
            <div class="heading">
                <h1><span class="notebook">Stanford:</span>
                                    Natural Language Processing</h1>
            </div>
            <hr>
            <div class="menu">
                <ul>
<li><a href="../../index.html" title="index">index</a></li>
<ul>
<li><a href="../Civil_Engineering.html" title="Civil Engineering">Civil Engineering</a></li>
<li><a href="../Complex_Systems.html" title="Complex Systems">Complex Systems</a></li>
<li><a href="../Computer_Science.html" title="Computer Science">Computer Science</a></li>
<ul>
<li><a href="./Artificial_Intelligence.html" title="Artificial Intelligence">Artificial Intelligence</a></li>
<li><a href="./Computer_Science_101.html" title="Computer Science 101">Computer Science 101</a></li>
<li><a href="./Computer_Security.html" title="Computer Security">Computer Security</a></li>
<li><a href="./Cryptography.html" title="Cryptography">Cryptography</a></li>
<li><a href="./Design_and_Analysis_of_Algorithms_I.html" title="Design and Analysis of Algorithms I">Design and Analysis of Algorithms I</a></li>
<li><a href="./Game_Theory.html" title="Game Theory">Game Theory</a></li>
<li><a href="./Human-Computer_Interaction.html" title="Human-Computer Interaction">Human-Computer Interaction</a></li>
<li><a href="./Introduction_to_Databases.html" title="Introduction to Databases">Introduction to Databases</a></li>
<li><a href="./Machine_learning.html" title="Machine learning">Machine learning</a></li>
<li><strong>Natural Language Processing</strong></li>
<li><a href="./Probabilistic_Graphical_Models.html" title="Probabilistic Graphical Models">Probabilistic Graphical Models</a></li>
<li><a href="./Software_as_a_Service.html" title="Software as a Service">Software as a Service</a></li>
</ul>
<li><a href="../Electrical_Engr..html" title="Electrical Engr.">Electrical Engr.</a></li>
<li><a href="../Entrepreneurship.html" title="Entrepreneurship">Entrepreneurship</a></li>
<li><a href="../Medicine.html" title="Medicine">Medicine</a></li>
</ul>
</ul>

            </div>
            <div class="content">
            <!-- Wiki content -->
                <p>
<img src="./pasted_image004.jpg" alt=""><br>
</p>

<h2>Homepage</h2>

<p>
<a href="http://www.nlp-class.org/" title="http://www.nlp-class.org/">http://www.nlp-class.org/</a><br>
</p>

<h2>Schedule</h2>

<p>
<ul>
<li>Starts: 23/01/2012</li>
<li>Ends: 18/03/2011</li>
</ul>
</p>

<h2>Instructors</h2>

<p>
<ul>
<li><a href="http://www.stanford.edu/~jurafsky/" title="Dan Jurafsky">Dan Jurafsky</a> is Professor of Linguistics and Professor by Courtesy of Computer Science at Stanford University. Dan received his Bachelors degree in Linguistics in 1983 and his Ph.D. in Computer Science in 1992, both from the University of California at Berkeley, and also taught at the University of Colorado, Boulder before joining the Stanford faculty in 2004. He is the recipient of a MacArthur Fellowship and has served on a variety of editorial boards, corporate advisory boards, and program committees. Dan's research extends broadly throughout natural language processing as well as its application to the behavioral and social sciences.</li>
<li><a href="http://nlp.stanford.edu/~manning/" title="Christopher Manning">Christopher Manning</a> is an Associate Professor of Computer Science and Linguistics at Stanford University. Chris received a Bachelors degree and University Medal from the Australian National University and a Ph.D. from Stanford in 1994, both in Linguistics. Chris taught at Carnegie Mellon University and The University of Sydney before joining the Stanford faculty in 1999. He is a Fellow of the American Association for Artificial Intelligence, and is one of the most cited authors in natural language processing, for his research on a broad range of statistical natural language topics from tagging and parsing to grammar induction and text understanding.</li>
</ul>
</p>

<h2>Description</h2>

<p>
Natural language processing is the technology for dealing with our most ubiquitous product: human language, as it appears in emails, web pages, tweets, product descriptions, newspaper stories, social media, and scientific articles, in thousands of languages and varieties. In the past decade, successful natural language processing applications have become part of our everyday experience, from spelling and grammar correction in word processors to machine translation on the web, from email spam detection to automatic question answering, from detecting people's opinions about products or services to extracting appointments from your email. In this class, you'll learn the fundamental algorithms and mathematical models for human language processing and how you can use them to solve practical problems in dealing with language data wherever you encounter it.<br>
</p>

<h2>Include</h2>

<p>
<ul>
<li>screencast lecture videos</li>
<li>quiz questions</li>
<li>assignments</li>
<li>exams</li>
<li>regular feedback</li>
<li>discussion forum</li>
</ul>
</p>

<h2>Provides</h2>

<p>
<ul>
<li>word and sentence tokenization</li>
<li>text classification</li>
<li>sentiment analysis</li>
<li>spelling correction</li>
<li>information extraction</li>
<li>parsing</li>
<li>meaning extraction</li>
<li>question answering</li>
<li>underlying theory from probability, statistics, machine learning that are crucial for the field</li>
<li>fundamental algorithms like n-gram language modeling, naive bayes, maxent classifiers</li>
<li>sequence models like Hidden Markov Models</li>
<li>probabilistic dependency and constituent parsing</li>
<li>vector-space models of meaning.</li>
</ul>
</p>

<h2>Requires</h2>

<p>
<ul>
<li>probability (know Bayes rule)</li>
<li>vectors and vector spaces (could length normalize a vector)</li>
<li>calculus (know that the derivative of a function is zero at a maximum or minimum of a function)</li>
<li>programming ability (know about hash tables and graph data structures)</li>
<li>knowledge of Java or Python</li>
</ul>
</p>

<h2>Bibliograpy</h2>

<p>
<ul>
<li>lectures and notes</li>
<li>Jurafsky and Martin, Speech and Language Processing 2nd Edition</li>
<li>Manning, Schütze and Raghavan 2008</li>
<li>Manning and Schütze 1999</li>
<li>Klein and Loper 2009</li>
</ul>
</p>


            <!-- End wiki content -->
            </div>
            <hr>
            <!-- Backlinks -->
            <div class="footer">
                Backlinks:
            <!-- End Backlinks -->
            </div>
        </div>
    </body>
</html>
